{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-02T16:39:06.414699Z","iopub.execute_input":"2023-10-02T16:39:06.415108Z","iopub.status.idle":"2023-10-02T16:39:06.430323Z","shell.execute_reply.started":"2023-10-02T16:39:06.415071Z","shell.execute_reply":"2023-10-02T16:39:06.429184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# loading the dataset\ndata = pd.read_csv('/kaggle/input/stroke-prediction-data/heart_strokes.csv')","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:39:06.432307Z","iopub.execute_input":"2023-10-02T16:39:06.432869Z","iopub.status.idle":"2023-10-02T16:39:06.498000Z","shell.execute_reply.started":"2023-10-02T16:39:06.432837Z","shell.execute_reply":"2023-10-02T16:39:06.497067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loading Libraries\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom imblearn.over_sampling import RandomOverSampler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:39:06.499238Z","iopub.execute_input":"2023-10-02T16:39:06.499790Z","iopub.status.idle":"2023-10-02T16:39:06.505348Z","shell.execute_reply.started":"2023-10-02T16:39:06.499758Z","shell.execute_reply":"2023-10-02T16:39:06.504432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking the first few observations\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:39:06.506502Z","iopub.execute_input":"2023-10-02T16:39:06.507268Z","iopub.status.idle":"2023-10-02T16:39:06.531406Z","shell.execute_reply.started":"2023-10-02T16:39:06.507233Z","shell.execute_reply":"2023-10-02T16:39:06.530420Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data exploration \ndata.describe()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:39:06.534746Z","iopub.execute_input":"2023-10-02T16:39:06.535715Z","iopub.status.idle":"2023-10-02T16:39:06.568429Z","shell.execute_reply.started":"2023-10-02T16:39:06.535681Z","shell.execute_reply":"2023-10-02T16:39:06.567337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:39:06.569823Z","iopub.execute_input":"2023-10-02T16:39:06.570179Z","iopub.status.idle":"2023-10-02T16:39:06.589828Z","shell.execute_reply.started":"2023-10-02T16:39:06.570150Z","shell.execute_reply":"2023-10-02T16:39:06.588796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check for duplicates\nprint(data.duplicated())","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:39:06.591184Z","iopub.execute_input":"2023-10-02T16:39:06.591484Z","iopub.status.idle":"2023-10-02T16:39:06.615723Z","shell.execute_reply.started":"2023-10-02T16:39:06.591455Z","shell.execute_reply":"2023-10-02T16:39:06.614828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check the missing values.\nprint(data.isna().sum())","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:39:06.616804Z","iopub.execute_input":"2023-10-02T16:39:06.617486Z","iopub.status.idle":"2023-10-02T16:39:06.634416Z","shell.execute_reply.started":"2023-10-02T16:39:06.617465Z","shell.execute_reply":"2023-10-02T16:39:06.633544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# replace missing calues in dataset with median and mode\nsmoking_status_mode = data['smoking_status'].mode()[0]\ndata['smoking_status'].fillna(smoking_status_mode, inplace=True)\nbmi_median = data['bmi'].median()\ndata['bmi'].fillna(bmi_median, inplace=True)\nprint(data.isna().sum())","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:39:06.635545Z","iopub.execute_input":"2023-10-02T16:39:06.635835Z","iopub.status.idle":"2023-10-02T16:39:06.659242Z","shell.execute_reply.started":"2023-10-02T16:39:06.635809Z","shell.execute_reply":"2023-10-02T16:39:06.658357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data encoding\n# all ordinal categorical data will be encoded with the label encoding strategy \n\ndata['ever_married'] = data['ever_married'].replace({'Yes':1, 'No':0}).astype(np.uint8)\ndata['gender'] = data['gender'].replace({'Male':0,'Female':1,'Other':-1}).astype(np.uint8)\ndata['Residence_type'] = data['Residence_type'].replace({'Rural':0,'Urban':1}).astype(np.uint8)\ndata['work_type'] = data['work_type'].replace({'Private':0,'Self-employed':1,'Govt_job':2,'children':3,'Never_worked':4}).astype(np.uint8)\ndata['smoking_status'] = data['smoking_status'].replace({'smokes':3,'formerly smoked':2, 'never smoked':1, 'Unknown':0}).astype(np.uint8)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:39:06.660374Z","iopub.execute_input":"2023-10-02T16:39:06.660903Z","iopub.status.idle":"2023-10-02T16:39:06.738104Z","shell.execute_reply.started":"2023-10-02T16:39:06.660875Z","shell.execute_reply":"2023-10-02T16:39:06.737265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check how balanced the data is\nprint(data['stroke'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:39:06.739169Z","iopub.execute_input":"2023-10-02T16:39:06.739470Z","iopub.status.idle":"2023-10-02T16:39:06.745386Z","shell.execute_reply.started":"2023-10-02T16:39:06.739442Z","shell.execute_reply":"2023-10-02T16:39:06.744529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:39:06.746561Z","iopub.execute_input":"2023-10-02T16:39:06.747078Z","iopub.status.idle":"2023-10-02T16:39:06.766993Z","shell.execute_reply.started":"2023-10-02T16:39:06.747050Z","shell.execute_reply":"2023-10-02T16:39:06.766086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Understanding the data better. Goal is to check the correlation between the attributes.\n\ndata_correlation_matrix = data.corr() \n# Create a heatmap of the correlation matrix\nplt.figure(figsize=(16, 8))\nsns.heatmap(data_correlation_matrix, annot=True, cmap='crest', linewidths=0.5)\nplt.title('Dataset Correlation Heatmap')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:39:06.768442Z","iopub.execute_input":"2023-10-02T16:39:06.769163Z","iopub.status.idle":"2023-10-02T16:39:07.430701Z","shell.execute_reply.started":"2023-10-02T16:39:06.769061Z","shell.execute_reply":"2023-10-02T16:39:07.429834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Separation\nX = data.drop(columns=['stroke'])\ny = data['stroke']\nX.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:39:07.434814Z","iopub.execute_input":"2023-10-02T16:39:07.435384Z","iopub.status.idle":"2023-10-02T16:39:07.457139Z","shell.execute_reply.started":"2023-10-02T16:39:07.435350Z","shell.execute_reply":"2023-10-02T16:39:07.454983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head(5)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:39:07.459740Z","iopub.execute_input":"2023-10-02T16:39:07.461135Z","iopub.status.idle":"2023-10-02T16:39:07.478970Z","shell.execute_reply.started":"2023-10-02T16:39:07.461104Z","shell.execute_reply":"2023-10-02T16:39:07.477967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Normalization of the columns/attributes age and avg_glucose_level\n\n# age_list = X['age'].values\n# avg_glucose_level = X['avg_glucose_level'].values\n\n# age_result = [value / age_list.max() for value in age_list]\n# glucose_level_result = [value / avg_glucose_level.max() for value in avg_glucose_level]\n# X['age'] = age_result\n# X['avg_glucose_level'] = glucose_level_result","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-10-02T16:39:07.480195Z","iopub.execute_input":"2023-10-02T16:39:07.480770Z","iopub.status.idle":"2023-10-02T16:39:07.486293Z","shell.execute_reply.started":"2023-10-02T16:39:07.480738Z","shell.execute_reply":"2023-10-02T16:39:07.485209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:39:07.487759Z","iopub.execute_input":"2023-10-02T16:39:07.488383Z","iopub.status.idle":"2023-10-02T16:39:07.510969Z","shell.execute_reply.started":"2023-10-02T16:39:07.488349Z","shell.execute_reply":"2023-10-02T16:39:07.509817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscalar = StandardScaler(with_mean=False,with_std=False)\nscaled_data = scalar.fit_transform([X['age'], X['avg_glucose_level']])\nX['age'], X['avg_glucose_level'] = scaled_data[0], scaled_data[1]","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:39:07.512573Z","iopub.execute_input":"2023-10-02T16:39:07.513285Z","iopub.status.idle":"2023-10-02T16:39:07.523631Z","shell.execute_reply.started":"2023-10-02T16:39:07.513249Z","shell.execute_reply":"2023-10-02T16:39:07.522486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:39:07.525640Z","iopub.execute_input":"2023-10-02T16:39:07.526283Z","iopub.status.idle":"2023-10-02T16:39:07.544476Z","shell.execute_reply.started":"2023-10-02T16:39:07.526246Z","shell.execute_reply":"2023-10-02T16:39:07.543499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score\n\nX_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.8, random_state=42)\ny_train = y_train.values \n\nprint(X.shape)\nprint(X_train.shape)\nprint(X_test.shape)\n\nprint(y_train)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:39:07.545859Z","iopub.execute_input":"2023-10-02T16:39:07.546543Z","iopub.status.idle":"2023-10-02T16:39:07.562358Z","shell.execute_reply.started":"2023-10-02T16:39:07.546489Z","shell.execute_reply":"2023-10-02T16:39:07.561355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model Creation and testing \nrf_classifier = RandomForestClassifier(random_state=42)\nrf_classifier.fit(X_train, y_train)\npred = rf_classifier.predict(X_test)\nfirst_acc = accuracy_score(y_test, pred)\nfirst_precision = precision_score(y_test, pred, average='macro', zero_division=0)\nfirst_recall = recall_score(y_test, pred, average='macro')\nfirst_f1 = f1_score(y_test, pred, average='macro')\nprint('Accuracy: ', first_acc)\nprint('Precision: ', first_precision)\nprint('Recall: ', first_recall)\nprint('F1: ', first_f1)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:39:07.563857Z","iopub.execute_input":"2023-10-02T16:39:07.564462Z","iopub.status.idle":"2023-10-02T16:39:10.653772Z","shell.execute_reply.started":"2023-10-02T16:39:07.564428Z","shell.execute_reply":"2023-10-02T16:39:10.652819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Random oversampling\noversampler = RandomOverSampler(sampling_strategy=0.75, random_state=42)\n\n# Data for oversampling\nX_r, y_r = oversampler.fit_resample(X, y)\n\nX_r_train, X_r_test, y_r_train, y_r_test = train_test_split(X_r, y_r, train_size=0.8, random_state=42)\ny_r_train = y_r_train.values\n\nr_scalar = StandardScaler(with_mean=False,with_std=False)\nr_scaled_data = r_scalar.fit_transform([X_r['age'], X_r['avg_glucose_level']])\nX_r['age'], X_r['avg_glucose_level'] = r_scaled_data[0], r_scaled_data[1]","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:39:10.655403Z","iopub.execute_input":"2023-10-02T16:39:10.655847Z","iopub.status.idle":"2023-10-02T16:39:10.701908Z","shell.execute_reply.started":"2023-10-02T16:39:10.655809Z","shell.execute_reply":"2023-10-02T16:39:10.700965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking how balanced the data is after random oversamping\nprint(y_r.value_counts())","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:39:10.703411Z","iopub.execute_input":"2023-10-02T16:39:10.703806Z","iopub.status.idle":"2023-10-02T16:39:10.710519Z","shell.execute_reply.started":"2023-10-02T16:39:10.703772Z","shell.execute_reply":"2023-10-02T16:39:10.709434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Pseudocode for Random Forest\n# RandomForestClassifier:\n#     Input:\n#         - Training data (X_train, y_train)\n#         - Number of trees in the forest (n_estimators)\n#         - Number of features to consider at each split (max_features)\n#         - Number of data points to sample for each tree (bootstrap_samples)\n\n#     Output:\n#         - Random forest ensemble\n\n#     Ensemble = []  # Initialize an empty list to store decision trees\n\n#     for i = 1 to n_trees:\n#         # Randomly sample data points with replacement (bootstrap)\n#         X_bootstrap, y_bootstrap = BootstrapSample(X_train, y_train, bootstrap_samples)\n\n#         # Randomly select a subset of features\n#         selected_features = RandomSubset(max_features, total_features)\n\n#         # Train a decision tree on the bootstrapped dataset using the selected features\n#         tree = BuildDecisionTree(X_bootstrap, y_bootstrap, selected_features)\n\n#         # Append the trained tree to the ensemble\n#         Ensemble.append(tree)\n\n#     return Ensemble\n\n# Predict:\n#     Input:\n#         - Random forest ensemble\n#         - Input data (X_test)\n\n#     Output:\n#         - Predicted class labels (or regression values)\n\n#     Initialize an array to store the predictions for each tree: predictions = []\n\n#     for tree in Ensemble:\n#         # Make predictions using each tree in the ensemble\n#         y_pred_tree = tree.predict(X_test)\n        \n#         # Append the predictions to the array\n#         predictions.append(y_pred_tree)\n\n#     # Aggregate the predictions (e.g., majority vote for classification)\n#     final_predictions = Aggregate(predictions)\n\n#     return final_predictions","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:39:10.712166Z","iopub.execute_input":"2023-10-02T16:39:10.712525Z","iopub.status.idle":"2023-10-02T16:39:10.731482Z","shell.execute_reply.started":"2023-10-02T16:39:10.712492Z","shell.execute_reply":"2023-10-02T16:39:10.730571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Hyper Parameter tunning\n# Define the hyperparameter grid to search\nparam_grid = {\n    'n_estimators': [10, 50, 100, 200], # Number of trees in the forest\n    'max_depth': [None, 10, 20, 30],    # Maximum depth of the trees\n    'min_samples_split': [2, 5, 10],    # Minimum number of samples required to split an internal node\n    'min_samples_leaf': [1, 2, 4]       # Minimum number of samples required to be at a leaf node\n}\n\n# Create a GridSearchCV object\ngrid_search = GridSearchCV(rf_classifier, param_grid, cv=5, scoring='accuracy')\n\n# Fit GridSearchCV to the data\ngrid_search.fit(X_r_train, y_r_train)\n\n# Get the best hyperparameters\nbest_params = grid_search.best_params_\nprint(\"Best Hyperparameters:\", best_params)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:39:10.732666Z","iopub.execute_input":"2023-10-02T16:39:10.733417Z","iopub.status.idle":"2023-10-02T17:21:06.057196Z","shell.execute_reply.started":"2023-10-02T16:39:10.733395Z","shell.execute_reply":"2023-10-02T17:21:06.056256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train a final Random Forest classifier with the best hyperparameters\nbest_rf_classifier = RandomForestClassifier(random_state=42, **best_params)\nbest_rf_classifier.fit(X_r_train, y_r_train)\n\n# Make predictions with the final model on the validation set\ny_pred = best_rf_classifier.predict(X_r_test)\n\n# Evaluate the model's performance\naccuracy = accuracy_score(y_r_test, y_pred)\nprecision = precision_score(y_r_test, y_pred, average='macro', zero_division=0)\nrecall = recall_score(y_r_test, y_pred, average='macro')\nf1 = f1_score(y_r_test, y_pred, average='macro')\nprint('Accuracy: ', accuracy)\nprint('Precision: ', precision)\nprint('Recall: ', recall)\nprint('F1: ', f1)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:21:06.058803Z","iopub.execute_input":"2023-10-02T17:21:06.059158Z","iopub.status.idle":"2023-10-02T17:21:16.119118Z","shell.execute_reply.started":"2023-10-02T17:21:06.059126Z","shell.execute_reply":"2023-10-02T17:21:16.118150Z"},"trusted":true},"execution_count":null,"outputs":[]}]}